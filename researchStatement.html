<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ali Hamdi | Research Statement</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="style.css">
</head>
<body>
<nav class="navbar">
    <div class="nav-container">
        <a href="index.html" class="nav-logo"><img src="profile.jpeg" alt="Ali Hamdi" class="sm-profile-img"> Ali Hamdi</a>


        <button class="nav-toggle" id="navToggle">
            <i class="fas fa-bars"></i>
        </button>

        <ul class="nav-menu" id="navMenu">
            <li class="nav-item">
                <a href="index.html" class="nav-link">Home</a>
            </li>
            <li class="nav-item">
                <a href="publications.html" class="nav-link">Publications</a>
            </li>
            <li class="nav-item">
                <a href="experience.html" class="nav-link">Academic</a>
            </li>
            <li class="nav-item">
                <a href="industry.html" class="nav-link">Industry</a>
            </li>
            <li class="nav-item">
                <a href="awards.html" class="nav-link">Awards</a>
            </li>
            <li class="nav-item">
                <a href="researchStatement.html" class="nav-link active">Research Statement</a>
            </li>
            <li class="nav-item">
                <a href="teachingPhilosophy.html" class="nav-link">Teaching</a>
            </li>
            <li class="nav-item">
                <a href="supervision.html" class="nav-link">Supervision</a>
            </li>
        </ul>
    </div>
</nav>

<div class="container">
    <aside class="sidebar sm-hidden">
        <img src="profile.jpeg" alt="Ali Hamdi" class="profile-img">
        <div class="sidebar-name">Ali Hamdi</div>
        <div class="sidebar-title">Assistant Professor | Chief Technology Officer</div>
        <div class="sidebar-bio">
            AI researcher and technology executive with 17+ years experience in artificial intelligence, machine learning, computer vision, and natural language processing.
        </div>
        <ul class="sidebar-links">
            <li><a href="mailto:alihamdi@gmail.com"><i class="fas fa-envelope"></i> alihamdi@gmail.com</a></li>
            <li><a href="tel:+201016936293"><i class="fas fa-phone"></i> +201016936293</a></li>
            <li><a href="https://www.linkedin.com/in/ali7amdi/" target="_blank"><i class="fab fa-linkedin"></i> LinkedIn</a></li>
            <li><a href="https://scholar.google.com.au/citations?user=Q5qW1rcAAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i> Google Scholar</a></li>
            <li><a href="https://www.researchgate.net/profile/Ali-Hamdi-2" target="_blank"><i class="fab fa-researchgate"></i> ResearchGate</a></li>
            <li><a href="https://github.com/ali7amdi" target="_blank"><i class="fab fa-github"></i> GitHub</a></li>
            <li><a href="https://youtube.com/ali7amdi" target="_blank"><i class="fa-brands fa-youtube"></i> YouTube</a></li>
            <li><a href="https://wa.me/+61451798166" target="_blank"><i class="fa-brands fa-whatsapp"></i> WhatsApp</a></li>
        </ul>
    </aside>


    <main class="main-content">
            <section id="research-statement">
                <h1>Research Statement</h1>
                <h2>Overview & Vision</h2>
                <p>My research is driven by a fundamental question: How can artificial intelligence systems meaningfully perceive, understand, and interact with complex, uncertain, and multimodal environments—especially in low-resource and high-impact domains?</p>
                
                <p>I focus on applied AI, with emphasis on:</p>
                <ul>
                    <li>Natural Language Processing (LLMs, summarization, multilingual sentiment, stance detection)</li>
                    <li>Computer Vision (biomedical imaging, drone perception, object tracking)</li>
                    <li>Multimodal and Spatiotemporal Learning (graphs, time-series, attention)</li>
                    <li>Responsible AI (fairness, hallucination detection, low-resource representation)</li>
                </ul>
                
                <h2>Key Research Themes</h2>
                
                <h3>1. Large Language Models (LLMs) & NLP Applications</h3>
                <p>My work explores optimizing LLM outputs for summarization, sentiment, and QA, including:</p>
                <ul>
                    <li>LexiSem, a hybrid re-ranker balancing semantic depth with lexical quality (Neurocomputing 2024)</li>
                    <li>Arabic NLP advancements via surveys, frameworks (e.g., CLASENTI), and SemEval wins</li>
                    <li>Current focus: LLM alignment, hallucination detection (SemEval 2025), and multilingual fine-tuning</li>
                </ul>
                
                <h3>2. Multimodal Perception & Decision Systems</h3>
                <p>I explore learning across modalities—text, speech, time, space:</p>
                <ul>
                    <li>MARL: Attentional fusion for clinical diagnosis (ICCV Systems)</li>
                    <li>CLASEG: Oral lesion detection integrating classification & segmentation (Scientific Reports)</li>
                    <li>Drone-based tracking (DroTrack) and predictive modeling in uncertain settings</li>
                </ul>
                
                <h3>3. Graph-Based and Spatial AI</h3>
                <p>My research introduces novel graph neural architectures for contextual learning:</p>
                <ul>
                    <li>Proposed representing spatial-temporal dynamics in crowd and infrastructure monitoring</li>
                    <li>Designed dynamic graph applications in health and traffic</li>
                </ul>
                
                <h3>4. Applied AI in Societal Contexts</h3>
                <p>Collaborating on cross-disciplinary projects:</p>
                <ul>
                    <li>Health-aware route planning (Asthma AI)</li>
                    <li>LLMs in drone operations, education, and automation (LMV-RPA, Quranic QA)</li>
                    <li>AI for agriculture, natural language understanding, monitoring and inspection</li>
                </ul>
                
                <h2>Impact & Recognition</h2>
                <ul>
                    <li>Published 70+ peer-reviewed papers (AI Review, IEEE TSC, Neurocomputing, ACL)</li>
                    <li>1st Place Winner, SemEval-2025 Shared Task (LLM hallucination detection)</li>
                    <li>Supervised 5 PhDs, 15+ master's, 50+ bachelor's projects</li>
                    <li>Research featured in CORE A/Q1 venues* and applied in production AI systems</li>
                    <li>Led or co-led grants totaling $900k+ (QNRF, ARG, collaborations across MENA & ANZ)</li>
                </ul>
                
                <h2>Future Research Trajectory</h2>
                <ol>
                    <li>LLM Evaluation & Alignment → Multilingual hallucination & bias detection</li>
                    <li>Augmented Perception for Robotics → Drones, medical wearables, and human-AI symbiosis</li>
                    <li>Spatiotemporal Learning for Resilient Cities → Graph AI for traffic, infrastructure, and health</li>
                </ol>
            </section>
        </main>
    </div>

<script src="style.js"></script>

</body>
</html>